# -*- coding: utf-8 -*-
"""Projekt - analiza na podstawie datasetu FM 2022 v.2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gz0RhZ92lciIU0ztmdms8pkW8V1I49xc

#Cel projektu.

W niniejszym projekcie postawiłem sobie za cel zbadanie zależności występujących w grze Football Manager 2022, a zachodzących między dystansem średnio przez piłkarzy w meczu oraz ich ogólną celnością podań, liczoną w procentach, a przeciętną liczbą podań kluczowych i asyst na mecz.

Należy sobie zdefiniować pojęcie **podania kluczowego**, gdyż może ono nie być jasne. Wśród teoretyków futbolu nie ma pełnej zgody co do definicji takowego zagrania, jednak większość opowiada się za takim rozumieniem, wedle którego podaniem kluczowym jest podanie, które stwarza koledze z zespołu możliwość oddania strzału, który jednak nie kończy się golem. To właśnie brak rezultatu w postaci bramki odróżnia kluczowe podanie od **asysty**. Połączone jednak ze sobą te dwa współczynniki pozwalają na wymierną ocenę kreatywności gracza w ofensywie. Wydaje się być uzasadnione powiązanie zagrożenia stwarzanego bezpośrednio wykonywanymi przez gracza podaniami z jego ruchliwością i liczbą wykonywanych przez niego podań - w teorii zawodnik dokładniejszy i taki, który operuje w większej liczbie sektorów boiska, zwiększa swoje prawdopodobieństwo uczestniczenia w akcji ofensywnej i zapewnia sobie w ten sposób możliwość częstszego znajdowania dobrze ustawionych w ofensywie partnerów.

Gry z serii Football Manager (FM), poza byciem bardzo grywalnymi, dobrze odwzorowują również zbliżony do rzeczywistego przebieg meczu, jak również aktualne trendy taktyczne w futbolu. Obserwacje poczynione na podstawie bazy danych z najbardziej aktualnej na chwilę obecną edycji - FM 2022 - mogą nasuwać wnioski dające się wykorzystać również w realnym świecie piłki nożnej.

W projekcie wykorzystuję bazę danych Football Manager 2022 Player Data, autorstwa Gabriela Abilleiry Rodrigeuza, dostępną pod adresem: https://www.kaggle.com/datasets/gabrielabilleira/football-manager-2022-player-data. Zapisana ona została na moim zdalnym repozytorium GitLab jako plik **variables.csv**.

#Przygotowanie danych i bibliotek.

W pierwszej kolejności należy - aby uniknąć problemów z wczytywaniem ProfileReport - zainstalować najbardziej aktualną wersję biblioteki pandas_profiling.
"""

!pip install pandas_profiling --upgrade
!pip install markupsafe==2.0.1

import numpy as np
import pandas as pd
from pandas_profiling import ProfileReport
import seaborn as sns
import matplotlib.pyplot as plt

!git clone https://gitlab.com/jakub_walczak/fm2022-key-passes-and-assists

!ls fm2022-key-passes-and-assists

"""Przystępujemy do wczytania pliku."""

df = pd.read_csv('fm2022-key-passes-and-assists/variables.csv')

df.sample(5)

df.info()

"""Jak widzimy, ramka danych df zawiera aż 45 kolumn, z czego znaczna większość będzie nieprzydatna z punktu widzenia naszej analizy. Nas interesować będą zaś kolumny dotyczące przeciętnych statystyk, jakie mogą mieć gracze ofensywni: 
- Hdr % (odsetek wygranych pojedynków główkowych), 
- Dist/Mins (odległość średnio pokonywana przez piłkarza w ciągu minuty), 
- Gls/90 (średnia liczba bramek zdobywanych na mecz), Shot % (odsetek strzałów celnych), 
- xG (expected goals, czyli oczekiwane bramki; zsumowany współczynnik zdobycia bramki przez piłkarzy w konkretnych sytuacjach, w których zawodnik oddaje strzał),
- Asts/90 (średnia liczba asyst na mecz),
- K Ps/90 (średnia liczba podań kluczowych na mecz),
- Pas % (odsetek celnych podań),
- Drb/90 (średnia liczba dryblingów na mecz),
- Gls/xG (odsetek bramek w stosunku do oczekiwanych bramek).

Pomocniczo, w celach wyodrębnienia danych do analizy, zastosowałem również kolumny:
- K Tck (kluczowe odbiory, tj. takie, które bezpośrednio zapobiegają zagrożeniu pod bramką; zastosowane, gdyż wysokimi wskaźnikami w tym elemencie gry legitymują się przeważnie obrońcy),
- Saves (obrony strzałów; zastosowane, gdyż jest to kolumna dotycząca wyłącznie bramkarzy).
"""

df = df[['Hdr %', 'Dist/Mins', 'Gls/90', 'Shot %', 'xG', 'Asts/90', 'K Ps/90', 'Pas %', 'K Tck', 'Drb/90', 'Saves', 'Gls/xG']]

df.describe()

"""Ponieważ wartości procentowe wskazane są w kolumnach jako części setne, mnożę je przez 100 dla lepszej czytelności. W tym samym celu wartości z kolumny Dist/Mins jako pomnożone przez 90 zostają zawarte w nowej kolumnie: Dist/Match. Wreszcie kolumny: K Ps/90 i Asts/90 zostają zsumowane w jedną: Key Ps & Asts/90. Z datasetu, wykorzystując kolumny Saves i K Tck, eliminujemy bramkarzy oraz obrońców. Po wykonaniu powyższych kroków można usunąć zbędne już kolumny."""

df['Pas %'] = df['Pas %']*100
df['Shot %'] = df['Shot %']*100
df['Hdr %'] = df['Hdr %']*100
df['Dist/Match'] = df['Dist/Mins']*90
df['Key Ps & Asts/90'] = df['K Ps/90'] + df['Asts/90']
df = df[df['Saves']<1]
df = df[df['K Tck']<3]

df.drop(columns=['Saves', 'Dist/Mins', 'K Tck', 'Asts/90', 'K Ps/90'], axis=1, inplace=True)

df.sample(5)

df.describe()

"""Z przedstawionych wyżej statystyk opisowych da się już przewidzieć rozkłady prawdopodobieństw poszczególnych zmiennych. Zmienną Pas % najprawdopodobniej da się opisać wg rozkładu normalnego, gdyż mediana i średnia są do siebie bardzo zbliżone, odchylenie standardowe wydaje się być stosunkowo niewielkie względem średniej, zaś różnice między kwartylami - nieznaczne. Podobnie, choć z nieco większymi różnicami i zapewne również bardziej skośnie, kształtować się powinien (na pierwszy rzut oka) rozkład zmiennych Dist/Match i Hdr %."""

df.info()

"""Ponieważ część rekordów została usunięta, wskazane jest dostosowanie numeracji indeksów do ich liczby. Pozwala to na zaoszczędzenie odrobiny pamięci."""

df.reset_index(drop=True, inplace=True)
df.info()

"""#EDA - analiza eksploracyjna danych.

Generujemy wbudowaną w bibliotekę Seaborn heatmapę, aby zobrazować korelację między poszczególnymi kolumnami. I tak:
- kolumna Dist/Match koreluje z Pas % i Key Ps & Asts/90 na poziomie odpowiednio 0.66 i 0.53,
- kolumna Pas % koreluje z Key Ps & Asts/90 na poziomie -0.039.
"""

cm = df.corr()
fig, ax = plt.subplots(figsize=(10,8))
sns.heatmap(cm, annot=True, ax=ax)

"""Następnie, z pomocą zaimportowanego z biblioteki pandas_profiling narzędzia ProfileReport, tworzymy rozbudowany raport szczegółowo analizujący poszczególne dane. Również ten raport potwierdza znaczną korelację między pokonywanym dystansem, a skutecznością podań i stwarzanym tymi podaniami zagrożeniem."""

report = ProfileReport(df, infer_dtypes=False)
report

"""W praktyce potwierdziło się, że rozkład zmiennej **Pas %** jest bardzo zbliżony do rozkładu normalnego. Jeżeli występują w nim wartości odstające, to wśród wartości najniższych i jest ich stosunkowo niewiele. Nie jest to jednak klasyczny rozkład normalny - tak jak rozkłady zmiennych **Hdr % i Dist/Match**, jest on w istocie **lewoskośny**, a więc w jego przypadku dominanta jest wyższa niż mediana, zaś mediana przewyższa średnią. W przypadku pozostałych zmiennych - **xG, Gls/90, Shot %, Drb/90 i Key Ps & Asts/90** mamy do czynienia z rozkładami **prawoskośnymi**, gdzie występuje zależność **średnia > mediana > dominanta**.

Taki rozkład poszczególnych zmiennych ma swoje źródło w ich powiązaniu z obrazowanymi przez nie elementami gry. Zmienne o rozkładzie lewoskośnym powiązane są z elementami gry mniej bezpośrednio wpływającymi na rezultaty w ofensywie aniżeli te, gdzie rozkład jest prawoskośny. Skuteczna gra w ataku jest znacznie bardziej wymagający niźli destrukcja akcji ofensywnych rywala.

#Regresja liniowa.

Rozpoczynamy od importu najpotrzebniejszych bibliotek z scikit-learna.
"""

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline

"""Definiujemy następnie kolumny, między którymi zależności badamy, a następnie dzielimy je na zbiory uczące i testowe."""

X = df[['Dist/Match', 'Pas %']]
y = df[['Key Ps & Asts/90']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

for column in X_train.columns:
  lower_percentile = X_train[column].quantile(0.06)
  
  X_train[column] = np.where(X_train[column] >= lower_percentile, 
                             X_train[column], lower_percentile)

"""Powołujemy instancje StandardScalera."""

sc_x = StandardScaler()
sc_y = StandardScaler()

X_train_std = sc_x.fit_transform(X_train)
y_train_std = sc_y.fit_transform(y_train.values.reshape(-1, 1))

"""Pipeline i GridSearchCV pozwalają, dzięki kroswalidacji, dobrać adekwatny wielomian dla regresji."""

pipe = Pipeline([('polynomial', PolynomialFeatures()), ('linear_regr', LinearRegression())])
parameters = {'polynomial__degree': [1,2,3,4,5,6,7,8,9,10]}
gs = GridSearchCV(pipe, param_grid=parameters, cv=10)

gs.fit(X_train_std, y_train_std)

print(gs.best_estimator_)
print(gs.best_params_)
print(gs.best_score_)

"""Pozbywamy się wartości odstających; ponieważ dane mogą być zniekształcone zasadniczo wyłącznie przez wartości bardzo niskie, wyłącznie je zastępujemy wartościami odpowiadającymi wartości przedstawianej przez percentyl 6%."""

for column in X_test.columns:
  lower_percentile = X_test[column].quantile(0.06)

  X_test[column] = np.where(X_test[column] >= lower_percentile, 
                             X_test[column], lower_percentile)

X_test_std = sc_x.transform(X_test)
y_test_std = sc_y.transform(y_test.values.reshape(-1, 1))

"""Obliczamy współczynnik determinancji; jak widać, współczynnik przedstawiany przez niniejszą regresję jest bardzo zbliżony do optymalnego wyniku modelu, na jaki wskazuje instancja GridSearchCV."""

print(gs.score(X_test_std, y_test_std))

"""Pora zatem na przewidywanie wyników - pobieramy próbkę danych ze zbioru testowego i predykujemy wartości na ich podstawie. Porównać je możemy "w miejscu", tworząc ramkę danych łączącą kolumny z wartością przewidzianą i realną."""

values_to_predict = X_test.sample(20)
values_to_predict2 = values_to_predict.reset_index()
values_to_predict2

predicted_values = pd.DataFrame(sc_y.inverse_transform(gs.predict(sc_x.transform(values_to_predict)).reshape(-1, 1)), columns=['Predicted Key Ps & Asts/90'])
true_values = pd.DataFrame(y.iloc[values_to_predict.index])
true_values.reset_index(drop=True, inplace=True)

pd.concat([predicted_values, true_values], axis=1, join='inner')

"""#Wyrysowanie wykresów regresji.

Aby wyrysować poszczególne wykresy, potrzebujemy dokonać oddzielnej predykcji dla każdej ze zmiennych zbioru **X_train**.
"""

x_1 = X_train[['Dist/Match']] 
x_2 = X_train[['Pas %']]

sc_x1 = StandardScaler()
sc_x2 = StandardScaler()
sc_y = StandardScaler()
x1_stand = sc_x1.fit_transform(x_1)
x2_stand = sc_x2.fit_transform(x_2)
y_stand = sc_y.fit_transform(y_train)

pf = PolynomialFeatures(degree=3)
X_1 = pf.fit_transform(x1_stand)

pf_2 = PolynomialFeatures(degree=4)
X_2 = pf_2.fit_transform(x2_stand)

lr = LinearRegression()
lr.fit(X_1, y_stand)

lr_2 = LinearRegression()
lr_2.fit(X_2, y_stand)

x1_sort = df[['Dist/Match']].sort_values(by='Dist/Match').values
x1_sort_std = sc_x1.transform(x1_sort)
x1_sort_pf = pf.transform(x1_sort_std)

x2_sort = df[['Pas %']].sort_values(by='Pas %').values
x2_sort_std = sc_x2.transform(x2_sort)
x2_sort_pf = pf_2.transform(x2_sort_std)

y1_pred = lr.predict(x1_sort_pf)

y2_pred = lr_2.predict(x2_sort_pf)

fig, ax = plt.subplots(figsize = (8,6))

ax.scatter(sc_x1.inverse_transform(x1_stand), sc_y.inverse_transform(y_stand), c='g')
ax.plot(sc_x1.inverse_transform(x1_sort_std), sc_y.inverse_transform(y1_pred), c='r')
ax.grid()
ax.set_ylim(ymin=-0.2, ymax=3.2)
ax.set_xlim(xmin=0.0)
plt.xlabel('Distance per match', fontsize=12)
plt.ylabel('Key passes + assists per match', fontsize=12)
plt.show()

"""Regresja w tym wypadku jest dość dokładna. Wyraźnie wskazuje ona, iż zagrożenie powodowane skutecznymi podaniami wyraźnie wzrasta wraz z liczbą przebiegniętych w meczu kilometrów przez zawodnika. Jak zaznaczyłem na wstępie, wraz z liczbą przebiegniętych kilometrów przez zawodnika rośnie również szansa, iż znajdzie się on w sektorze boiska, w którym może swoim zagraniem bezpośrednio zagrozić linii obronnej przeciwnika."""

fig, ax = plt.subplots(figsize = (8,6))

ax.scatter(sc_x2.inverse_transform(x2_stand), sc_y.inverse_transform(y_stand), c='g')
ax.plot(sc_x2.inverse_transform(x2_sort_std), sc_y.inverse_transform(y2_pred), c='r')

ax.grid()
ax.set_ylim(ymin=-0.2, ymax=3.2)
ax.set_xlim(xmin=79)
plt.xlabel('Passes on target percentage', fontsize=12)
plt.ylabel('Key passes + assists per match', fontsize=12)
plt.show()

"""Zależność między procentem celnych podań, a podaniami kluczowymi na mecz, jest trochę bardziej złożona. Linia regresji przebiega tu mniej więcej w połowie między wartościami maksymalnymi, a minimalnymi dla danego odsetka podań; wartości te rozkładają się równomiernie. Da się jednak zauważyć, iż wartości te wzrastają, począwszy od najmniejszych procentów podań, i przyjmują największe wartości w przedziale ok. 83-88%, po czym równomiernie spadają. Da się to uzasadnić następującymi czynnikami:
- zawodnicy z niższym od przeciętnej odsetkiem podań celnych mają słabszą technikę użytkową bądź mają inne zadania boiskowe (np. napastnicy mają za zadanie częściej strzelać niż podawać, jak również znacznie częściej operują w sektorach, w których przewagę liczebną ma rywal),
- zawodnicy z najwyższym odsetkiem podań rzadziej podejmują ryzyko przy podaniach do kolegów bądź ich zadaniem jest podawać piłkę do bardziej kreatywnych kolegów).

#Drzewko decyzyjne.

Zachowamy chronologię wizualizacji z poprzedniego segmentu. Rozpoczniemy ponownie od drzewka wyrysowującego zależność między pokonanym dystansem a podaniami zagrażającymi, potem przejdziemy do zależności tej drugiej zmiennej od procentowej skuteczności podań.
"""

from sklearn.tree import DecisionTreeRegressor
from sklearn import tree

x = df[['Dist/Match']]

dtr = DecisionTreeRegressor()

params = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8],
          'min_samples_split': [2, 3, 5, 10, 15]}

gs = GridSearchCV(dtr, param_grid=params, cv=10)
gs.fit(x,y)

gs.best_estimator_

dtr = DecisionTreeRegressor(min_samples_split=2, min_samples_leaf=5, max_depth=3)
dtr.fit(x,y)

x_fit = np.arange(x.values.min(), x.values.max(), 0.01)

dtr_pred = dtr.predict(x_fit.reshape(-1,1))

fig, ax = plt.subplots(figsize=(16,8))
ax.scatter(x, y)
ax.plot(x_fit, dtr_pred, c='r')
plt.xlabel('Distance per match')
plt.ylabel('Key passes + assists per match')
plt.show()

dtr.predict([[81], [87], [93]])

z = df[['Pas %']]
dtr2 = DecisionTreeRegressor()

params = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8],
          'min_samples_split': [2, 3, 5, 10, 15]}

gs2 = GridSearchCV(dtr2, param_grid=params, cv=10)
gs2.fit(z,y)

gs2.best_estimator_

dtr2 = DecisionTreeRegressor(min_samples_split=2, min_samples_leaf=5, max_depth=4)
dtr2.fit(z,y)

z_fit = np.arange(z.values.min(), z.values.max(), 0.01)

dtr2_pred = dtr2.predict(z_fit.reshape(-1,1))

fig, ax = plt.subplots(figsize=(25,8))
ax.scatter(z, y)
ax.plot(z_fit, dtr2_pred, c='r')
plt.xlabel('Passes on target percentage')
plt.ylabel('Key passes + assists per match')
plt.show()

dtr2.predict([[5], [9], [11], [13]])

fig = plt.figure(figsize=(50,40))
tree.plot_tree(dtr, feature_names=dtr.feature_names_in_, filled=True)
plt.show()

fig = plt.figure(figsize=(50,40))
tree.plot_tree(dtr2, feature_names=dtr2.feature_names_in_, filled=True)
plt.show()

"""Widać zatem, że analiza w postaci drzewek potwierdza wnioski wysunięte przy pomocy regresji liniowej, a nawet je uzupełnia.

#Wnioski końcowe.

Projekt wykazał, iż zależności między pomiędzy zmiennymi zależnymi w postaci dystansu pokonywanego przez zawodnika w meczu i jego ogólną skutecznością, a liczbą kluczowych podań i asyst na mecz są znaczące. Rozgrywającym idealnym w grze Football Manager 2022 wg powyższego modelu powinien być zawodnik pokonujący średnio min. 11 km w ciągu 90 minut (bazując na średnim dystansie w ciągu minuty) oraz zaliczającym między 85 a 90 procent celnych zagrań. Szukanie wzmocnień wśród rozgrywających powinno zatem oprzeć się w dużej mierze o powyższe statystyki; należy szukać zawodników może niekoniecznie bardzo dokładnych w przekazywaniu piłki partnerom, ale na pewno wybieganych. Stąd też, oprócz posiadanych zdolności, należy zwrócić uwagę również na wyżej opisane parametry, jak również na ulubione zagrania piłkarzy, opisane w odrębnych rubrykach dotyczących ich charakterystyki.
"""